{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1kjL8wUTvAe"
   },
   "source": [
    "# **Auxiliary Discriminator Training with 3D Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxpFKwDcTpqC"
   },
   "source": [
    "## Prepare necessary libraries and helper functions to build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93OZswxKM-F-",
    "outputId": "47ba0d46-8851-4e8c-9144-b10e3cf502a9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ================== IMPORT LIBRARIES ==================\n",
    "import os\n",
    "\n",
    "# This allow a silent import of Tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "from google_drive_downloader import GoogleDriveDownloader\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "print(\"Successfully Load All Libraries - Tensorflow Version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the directory where all the Json files are saved. \n",
    "data_files_directory = './data/chair_voxel_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrjQdCcZXMLl"
   },
   "source": [
    "Download the dataset. \n",
    "Each file is a JSON file that contains information of the geometry we converted from the ShapeNet dataset and the related ratings. \n",
    "\n",
    "The JSON file should have following properties: \n",
    "\n",
    "*   \"geometry\":  a multi-dimension array to represent the geometry. \n",
    "*   \"voxel_size\": the size of each voxels (should always equal to 1 in the context of this notebook)\n",
    "*   \"scaling_factor_from_original\": the scaling factor we used to scale the original mesh to produce this geometry\n",
    "*   \"geometry_shape\": a list representing the shape of the geometry. (should always be [32, 32, 64] in the context of this notebook)\n",
    "\n",
    "Ratings in the JSON files are as following: \n",
    "\n",
    "If the geometry is not given one of the ratings, the properties will note null\n",
    "*   \"stability_rating\": the stability rating as a float from 0 to 1\n",
    "*   \"aesthetic_rating\": the aesthetic rating as an integer from 0 to 10\n",
    "*   \"function_rating\": the function rating as an integer from 0 to 10\n",
    "\n",
    "Although the aesthetic_rating and function_rating are from 0 to 10 in the dataset. They should be normalized for the training, including the pretrained network should also produce a normalized rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If the directory exists and is not empty we presume the dataset is already on the local drive. \n",
    "# If not, we will download the dataset. \n",
    "\n",
    "download_dataset_from_google_drive = False\n",
    "\n",
    "if os.path.isdir(data_files_directory):\n",
    "    if not os.listdir(data_files_directory):\n",
    "        # Directory is empty\n",
    "        download_dataset_from_google_drive = True\n",
    "    else:    \n",
    "        # Directory is not empty\n",
    "        download_dataset_from_google_drive = False\n",
    "else:\n",
    "    # Given directory doesn't exist\n",
    "    download_dataset_from_google_drive = True\n",
    "    \n",
    "if download_dataset_from_google_drive:\n",
    "\n",
    "    # This will get download all the json files that contain geometry and rating information from google drive to the destination directory\n",
    "    GoogleDriveDownloader.download_file_from_google_drive(file_id='1DJzSfSWUDkAhuEfu706pm0riC6ho_5NS', \n",
    "                                                          dest_path=os.path.join(data_files_directory, 'chair_voxel_dataset.zip'),\n",
    "                                                          unzip=True)\n",
    "    data_files_directory = data_files_directory + 'chair_voxel_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the json file paths from the unzippped directory. \n",
    "data_file_paths = glob.glob(data_files_directory + \"*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files_with_stability_rating = []\n",
    "data_files_with_aesthetic_rating = []\n",
    "data_files_with_function_rating = []\n",
    "\n",
    "for data_file in data_file_paths:\n",
    "    with open(data_file) as json_file:\n",
    "        dictionary = json.load(json_file)\n",
    "        if dictionary[\"stability_rating\"] != None:\n",
    "            data_files_with_stability_rating.append(data_file)\n",
    "        if dictionary[\"aesthetic_rating\"] != None:\n",
    "            data_files_with_aesthetic_rating.append(data_file)\n",
    "        if dictionary[\"function_rating\"] != None:\n",
    "            data_files_with_function_rating.append(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} json files in total. \".format(len(data_file_paths)))\n",
    "print(\"There are {} files that have stability rating. \".format(len(data_files_with_stability_rating)))\n",
    "print(\"There are {} files that have aesthetic rating. \".format(len(data_files_with_aesthetic_rating)))\n",
    "print(\"There are {} files that have function rating. \".format(len(data_files_with_function_rating)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define several helper functions below that will facilitate building the tensorflow dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= HELPER FUNCTIONS ===================\n",
    "# This function can preview a geometry data using matplot lib\n",
    "def preview_geometries(geometry_data, plot_threshold=0.25, stability_model=None, aesthetic_model=None, function_model=None, save_plot_as_png=False, path_to_save=None):\n",
    "    # geometry_data must be an array of shape [32, 32, 64, 1]\n",
    "    if stability_model is not None:\n",
    "        stability_prediction = np.array(stability_model(np.expand_dims(geometry_data, axis=0)))[0][0]\n",
    "    else:\n",
    "        stability_prediction = None\n",
    "    \n",
    "    if aesthetic_model is not None:\n",
    "        aesthetic_prediction = np.array(aesthetic_model(np.expand_dims(geometry_data, axis=0)))[0][0]\n",
    "    else:\n",
    "        aesthetic_prediction = None\n",
    "    \n",
    "    if function_model is not None:\n",
    "        function_prediction = np.array(function_model(np.expand_dims(geometry_data, axis=0)))[0][0]\n",
    "    else:\n",
    "        function_prediction = None\n",
    "    \n",
    "    generation_title = \"Stability Prediction is {}\\nAesthetic Prediction is {}\\nFunction Prediction is {}\".format(str(stability_prediction), str(aesthetic_prediction), str(function_prediction))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "\n",
    "    data = np.squeeze(geometry_data, axis=-1)\n",
    "    for i in range(0, len(data)):\n",
    "        for j in range(0, len(data[i])):\n",
    "            for k in range(0, len(data[i][j])):\n",
    "                if data[i][j][k] >= plot_threshold:\n",
    "                    x.append(i)\n",
    "                    y.append(j)\n",
    "                    z.append(k)\n",
    "\n",
    "    z_c = z\n",
    "\n",
    "    # We decided to plot the results with a gradient color map so the depth and geometries are clearer to see. \n",
    "    from matplotlib.colors import ListedColormap\n",
    "\n",
    "    N = 256\n",
    "    vals = np.ones((N, 4))\n",
    "    vals[:, 0] = np.linspace(1, 0, N)\n",
    "    vals[:, 1] = np.linspace(43/N, 43/N, N)\n",
    "    vals[:, 2] = np.linspace(82/N, 82/N, N)\n",
    "    custom_cmp = ListedColormap(vals)\n",
    "\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    fig = plt.axes(projection='3d')\n",
    "    \n",
    "    # Data for three-dimensional scattered points\n",
    "    fig.scatter3D(np.array(x), np.array(y) * -1, np.array(z), cmap=custom_cmp, c=z_c)\n",
    "    fig.set_zlim(0,64)\n",
    "    fig.set_ylim(-64,0)\n",
    "    fig.set_xlim(0,64)\n",
    "    plt.title(generation_title);\n",
    "    if (save_plot_as_png):\n",
    "        plt.savefig(path_to_save + '.png')\n",
    "  \n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "# This function reads a custom dictionary data\n",
    "def read_json_file_geometry(filepath):\n",
    "    with open(filepath.numpy()) as json_file:\n",
    "        dictionary = json.load(json_file)\n",
    "\n",
    "    tensor = tf.convert_to_tensor(np.array(dictionary[\"geometry\"]), dtype=tf.float32)\n",
    "    tensor = tf.expand_dims(tensor, -1)\n",
    "    return tensor\n",
    "\n",
    "# This function returns the value of item in custom dictionary data from given key\n",
    "def read_json_file_stability(filepath):\n",
    "    with open(filepath.numpy()) as json_file:\n",
    "        dictionary = json.load(json_file)\n",
    "    tensor = tf.convert_to_tensor(np.array(dictionary[\"stability_rating\"]), dtype=tf.float32)\n",
    "    tensor = tf.expand_dims(tensor, -1)\n",
    "    return tensor\n",
    "\n",
    "# This function returns the value of item in custom dictionary data from given key\n",
    "def read_json_file_aesthetic(filepath):\n",
    "    with open(filepath.numpy()) as json_file:\n",
    "        dictionary = json.load(json_file)\n",
    "    tensor = tf.convert_to_tensor(np.array(dictionary[\"aesthetic_rating\"]), dtype=tf.float32) / 10\n",
    "    tensor = tf.expand_dims(tensor, -1)\n",
    "    return tensor\n",
    "\n",
    "# This function returns the value of item in custom dictionary data from given key\n",
    "def read_json_file_function(filepath):\n",
    "    with open(filepath.numpy()) as json_file:\n",
    "        dictionary = json.load(json_file)\n",
    "    tensor = tf.convert_to_tensor(np.array(dictionary[\"function_rating\"]), dtype=tf.float32) / 10\n",
    "    tensor = tf.expand_dims(tensor, -1)\n",
    "    return tensor\n",
    "\n",
    "# Function to build dataset without labels\n",
    "def build_dataset_w_labels(filepaths, label_name, batch_size):\n",
    "    file_list = tf.data.Dataset.list_files(filepaths)\n",
    "    ds_geometry = file_list.map(lambda x: tf.py_function(read_json_file_geometry, [x], Tout=tf.float32))\n",
    "    ds_label = None\n",
    "    if label_name == \"stability_rating\":\n",
    "        ds_label = file_list.map(lambda x: tf.py_function(read_json_file_stability, [x], Tout=tf.float32))\n",
    "        print(\"Building dataset with stability_rating as label\")\n",
    "    elif label_name == \"aesthetic_rating\":\n",
    "        ds_label = file_list.map(lambda x: tf.py_function(read_json_file_aesthetic, [x], Tout=tf.float32))\n",
    "        print(\"Building dataset with aesthetic_rating as label\")\n",
    "    elif label_name == \"function_rating\":\n",
    "        ds_label = file_list.map(lambda x: tf.py_function(read_json_file_function, [x], Tout=tf.float32))\n",
    "        print(\"Building dataset with function_rating as label\")\n",
    "    else:\n",
    "        print(\"No corresponding label find... Building dataset without label\")\n",
    "    \n",
    "    if ds_label != None:\n",
    "        ds = tf.data.Dataset.zip((ds_geometry, ds_label))\n",
    "        \n",
    "    ds = ds.shuffle(4, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(4)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability auxiliary discriminator training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= SET UP PARAMETERS ==================\n",
    "\n",
    "# Epochs\n",
    "epochs = 50\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Path of the directory where the trained weights of the network will be saved. \n",
    "auxiliary_discriminator_save_directory = './data/pretrained_models/chair_stability_auxiliary_discriminator/'\n",
    "\n",
    "# Create the directory to save the trained weights of the network. \n",
    "try:\n",
    "    os.makedirs(auxiliary_discriminator_save_directory)\n",
    "except FileExistsError:\n",
    "    print(\"The directory to save trained network weights already exists\")\n",
    "    \n",
    "# The path of log file that contains training information. \n",
    "training_log_location = './data/pretrained_models/chair_stability_auxiliary_discriminator/logs.txt'\n",
    "\n",
    "# Create a txt file to save losses during training\n",
    "try:\n",
    "    log_file = open(training_log_location, \"x\")\n",
    "    log_file.close()\n",
    "except FileExistsError:\n",
    "    print(\"Log file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} files that have stability rating. \".format(len(data_files_with_stability_rating)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how many samples will be used for stability auxiliary discriminator training\n",
    "num_training_samples = 4750\n",
    "\n",
    "# Define how many samples will be used for stability auxiliary discriminator validation\n",
    "num_validation_samples = 2027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tensorflow dataset\n",
    "\n",
    "train_ds = build_dataset_w_labels(data_files_with_stability_rating[0:num_training_samples], \"stability_rating\", batch_size)\n",
    "val_ds = build_dataset_w_labels(data_files_with_stability_rating[num_training_samples:num_training_samples + num_validation_samples], \"stability_rating\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can preview the first geometry in first batch as following\n",
    "\n",
    "for each_batch_geometry, each_batch_label in train_ds:\n",
    "    preview_geometries(each_batch_geometry[0], plot_threshold=0.25, stability_model=None, aesthetic_model=None, function_model=None, save_plot_as_png=False, path_to_save=None)\n",
    "    print(\"The label for this geometry is: {}\".format(each_batch_label[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ SET UP MACHINE LEARNING MODELS =========\n",
    "model = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.Conv3D(16, (4, 4, 4), strides=(2, 2, 2), padding='same', input_shape=(32, 32, 64, 1)), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(32, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(64, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(128, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1), \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),loss=tf.keras.losses.MeanSquaredError(reduction='sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=epochs, \n",
    "                    validation_data=val_ds, \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(auxiliary_discriminator_save_directory + \"epoch_{}\".format(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_log_location, \"a\") as log_file: \n",
    "\n",
    "    log_file.write(\"Batch Size for this training: {}\".format(batch_size))\n",
    "    log_file.write('\\n')\n",
    "    log_file.write(\"Learning Rate for this training: {}\".format(learning_rate))\n",
    "    \n",
    "    for i in range(0, len(history.history[\"loss\"])):\n",
    "        log_file.write('\\n')\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Epoch: \" + str(i))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Training loss: {:0.5f}\".format(history.history[\"loss\"][i]))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Validation loss: {:0.5f}\".format(history.history[\"val_loss\"][i]))\n",
    "    \n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training assessment and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Loss plot for auxiliary discriminator training\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discriminator_performance(labeled_dataset, sort_data = True):\n",
    "    yvalues1 = []\n",
    "    yvalues2 = []\n",
    "    \n",
    "    ds_iters = 0\n",
    "    \n",
    "    for each_batch_geometry, each_batch_labels in labeled_dataset:\n",
    "        \n",
    "        \n",
    "        yvalues1 += model.predict(each_batch_geometry).squeeze(1).tolist()\n",
    "        yvalues2 += np.array(each_batch_labels).squeeze(1).tolist()\n",
    "        \n",
    "        ds_iters += 1\n",
    "        \n",
    "        if ds_iters == int(num_training_samples/batch_size):\n",
    "            break\n",
    "    \n",
    "    zippedarray = sorted(zip(yvalues2, yvalues1)) #sorts both lists according to the first one (xvalues2 will be the labels)\n",
    "    sorted_yvalues2 = [x for x,y in zippedarray]\n",
    "    sorted_yvalues1 = [y for x,y in zippedarray]\n",
    "\n",
    "    #Plot \n",
    "    xvalues = range(0,len(yvalues1))\n",
    "    fig = plt.figure()\n",
    "\n",
    "    if (sort_data == True):\n",
    "        fig1 = plt.plot(xvalues, sorted_yvalues1, label='auxiliary_discriminator_predictions')\n",
    "        fig2 = plt.plot(xvalues, sorted_yvalues2, label='real_labels')\n",
    "\n",
    "    else:\n",
    "        fig1 = plt.plot(xvalues, yvalues1, label='auxiliary_discriminator_predictions')\n",
    "        fig2 = plt.plot(xvalues, yvalues2, label='real_labels')\n",
    "\n",
    "    plt.ylabel('rating')\n",
    "    plt.xlabel('data no.')  \n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Auxiliary Discriminator Performance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator_performance(val_ds, sort_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator_performance(train_ds, sort_data = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aesthetic auxiliary discriminator training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= SET UP PARAMETERS ==================\n",
    "\n",
    "# Epochs\n",
    "epochs = 100\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Path of the directory where the trained weights of the network will be saved. \n",
    "auxiliary_discriminator_save_directory = './data/pretrained_models/chair_aesthetic_auxiliary_discriminator/'\n",
    "\n",
    "# Create the directory to save the trained weights of the network. \n",
    "try:\n",
    "    os.makedirs(auxiliary_discriminator_save_directory)\n",
    "except FileExistsError:\n",
    "    print(\"The directory to save trained network weights already exists\")\n",
    "    \n",
    "# The path of log file that contains training information. \n",
    "training_log_location = './data/pretrained_models/chair_aesthetic_auxiliary_discriminator/logs.txt'\n",
    "\n",
    "# Create a txt file to save losses during training\n",
    "try:\n",
    "    log_file = open(training_log_location, \"x\")\n",
    "    log_file.close()\n",
    "except FileExistsError:\n",
    "    print(\"Log file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} files that have aesthetic rating. \".format(len(data_files_with_aesthetic_rating)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how many samples will be used for stability auxiliary discriminator training\n",
    "num_training_samples = 1910\n",
    "\n",
    "# Define how many samples will be used for stability auxiliary discriminator validation\n",
    "num_validation_samples = 814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tensorflow dataset\n",
    "\n",
    "train_ds = build_dataset_w_labels(data_files_with_aesthetic_rating[0:num_training_samples], \"aesthetic_rating\", batch_size)\n",
    "val_ds = build_dataset_w_labels(data_files_with_aesthetic_rating[num_training_samples:num_training_samples + num_validation_samples], \"aesthetic_rating\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can preview the first geometry in first batch as following\n",
    "\n",
    "for each_batch_geometry, each_batch_label in train_ds:\n",
    "    preview_geometries(each_batch_geometry[0], plot_threshold=0.25, stability_model=None, aesthetic_model=None, function_model=None, save_plot_as_png=False, path_to_save=None)\n",
    "    print(\"The label for this geometry is: {}\".format(each_batch_label[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ SET UP MACHINE LEARNING MODELS =========\n",
    "model = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.Conv3D(16, (4, 4, 4), strides=(2, 2, 2), padding='same', input_shape=(32, 32, 64, 1)), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(32, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(64, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Conv3D(128, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1), \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),loss=tf.keras.losses.MeanSquaredError(reduction='sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=epochs, \n",
    "                    validation_data=val_ds, \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(auxiliary_discriminator_save_directory + \"epoch_{}\".format(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_log_location, \"a\") as log_file: \n",
    "\n",
    "    log_file.write(\"Batch Size for this training: {}\".format(batch_size))\n",
    "    log_file.write('\\n')\n",
    "    log_file.write(\"Learning Rate for this training: {}\".format(learning_rate))\n",
    "    \n",
    "    for i in range(0, len(history.history[\"loss\"])):\n",
    "        log_file.write('\\n')\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Epoch: \" + str(i))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Training loss: {:0.5f}\".format(history.history[\"loss\"][i]))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Validation loss: {:0.5f}\".format(history.history[\"val_loss\"][i]))\n",
    "    \n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training assessment and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Loss plot for auxiliary discriminator training\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discriminator_performance(labeled_dataset, sort_data = True):\n",
    "    yvalues1 = []\n",
    "    yvalues2 = []\n",
    "    \n",
    "    ds_iters = 0\n",
    "    \n",
    "    for each_batch_geometry, each_batch_labels in labeled_dataset:\n",
    "        \n",
    "        \n",
    "        yvalues1 += model.predict(each_batch_geometry).squeeze(1).tolist()\n",
    "        yvalues2 += np.array(each_batch_labels).squeeze(1).tolist()\n",
    "        \n",
    "        ds_iters += 1\n",
    "        \n",
    "        if ds_iters == int(num_training_samples/batch_size):\n",
    "            break\n",
    "    \n",
    "    zippedarray = sorted(zip(yvalues2, yvalues1)) #sorts both lists according to the first one (xvalues2 will be the labels)\n",
    "    sorted_yvalues2 = [x for x,y in zippedarray]\n",
    "    sorted_yvalues1 = [y for x,y in zippedarray]\n",
    "\n",
    "    #Plot \n",
    "    plt.style.use('default')\n",
    "    text_color = 'black'\n",
    "    xvalues = range(0,len(yvalues1))\n",
    "    fig = plt.figure()\n",
    "\n",
    "    if (sort_data == True):\n",
    "        fig1 = plt.plot(xvalues, sorted_yvalues1, label='auxiliary_discriminator_predictions')\n",
    "        fig2 = plt.plot(xvalues, sorted_yvalues2, label='real_labels')\n",
    "\n",
    "    else:\n",
    "        fig1 = plt.plot(xvalues, yvalues1, label='auxiliary_discriminator_predictions')\n",
    "        fig2 = plt.plot(xvalues, yvalues2, label='real_labels')\n",
    "\n",
    "    plt.ylabel('Rating', color=text_color)\n",
    "    plt.xlabel('Data no.', color=text_color)  \n",
    "    plt.rc_context({'xtick.color' : text_color})\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Auxiliary Discriminator Performance\", color=text_color)\n",
    "    #plt.rcParams.update(colors('white'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator_performance(val_ds, sort_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator_performance(train_ds, sort_data = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function auxiliary discriminator training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= SET UP PARAMETERS ==================\n",
    "\n",
    "# Epochs\n",
    "epochs = 5\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Path of the directory where the trained weights of the network will be saved. \n",
    "auxiliary_discriminator_save_directory = './data/pretrained_models/chair_function_auxiliary_discriminator/'\n",
    "\n",
    "# Create the directory to save the trained weights of the network. \n",
    "try:\n",
    "    os.makedirs(auxiliary_discriminator_save_directory)\n",
    "except FileExistsError:\n",
    "    print(\"The directory to save trained network weights already exists\")\n",
    "    \n",
    "# The path of log file that contains training information. \n",
    "training_log_location = './data/pretrained_models/chair_function_auxiliary_discriminator/logs.txt'\n",
    "\n",
    "# Create a txt file to save losses during training\n",
    "try:\n",
    "    log_file = open(training_log_location, \"x\")\n",
    "    log_file.close()\n",
    "except FileExistsError:\n",
    "    print(\"Log file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} files that have function rating. \".format(len(data_files_with_function_rating)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how many samples will be used for stability auxiliary discriminator training\n",
    "num_training_samples = 1400\n",
    "\n",
    "# Define how many samples will be used for stability auxiliary discriminator validation\n",
    "num_validation_samples = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tensorflow dataset\n",
    "\n",
    "train_ds = build_dataset_w_labels(data_files_with_function_rating[0:num_training_samples], \"function_rating\", batch_size)\n",
    "val_ds = build_dataset_w_labels(data_files_with_function_rating[num_training_samples:num_training_samples + num_validation_samples], \"function_rating\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can preview the first geometry in first batch as following\n",
    "\n",
    "for each_batch_geometry, each_batch_label in train_ds:\n",
    "    preview_geometries(each_batch_geometry[0], plot_threshold=0.25, stability_model=None, aesthetic_model=None, function_model=None, save_plot_as_png=False, path_to_save=None)\n",
    "    print(\"The label for this geometry is: {}\".format(each_batch_label[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ SET UP MACHINE LEARNING MODELS =========\n",
    "model = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.Conv3D(16, (4, 4, 4), strides=(2, 2, 2), padding='same', input_shape=(32, 32, 64, 1)), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "   \n",
    "    tf.keras.layers.Conv3D(32, (4, 4, 4), strides=(2, 2, 2), padding='same'), \n",
    "    tf.keras.layers.LeakyReLU(), \n",
    "    tf.keras.layers.Dropout(0.3), \n",
    "   \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1), \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),loss=tf.keras.losses.MeanSquaredError(reduction='sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=epochs, \n",
    "                    validation_data=val_ds, \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(auxiliary_discriminator_save_directory + \"epoch_{}\".format(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_log_location, \"a\") as log_file: \n",
    "\n",
    "    log_file.write(\"Batch Size for this training: {}\".format(batch_size))\n",
    "    log_file.write('\\n')\n",
    "    log_file.write(\"Learning Rate for this training: {}\".format(learning_rate))\n",
    "    \n",
    "    for i in range(0, len(history.history[\"loss\"])):\n",
    "        log_file.write('\\n')\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Epoch: \" + str(i))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Training loss: {:0.5f}\".format(history.history[\"loss\"][i]))\n",
    "        log_file.write('\\n')\n",
    "        log_file.write(\"Validation loss: {:0.5f}\".format(history.history[\"val_loss\"][i]))\n",
    "    \n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training assessment and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Loss plot for auxiliary discriminator training\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discriminator_performance(labeled_dataset, sort_data = True):\n",
    "    yvalues1 = []\n",
    "    yvalues2 = []\n",
    "    \n",
    "    ds_iters = 0\n",
    "    \n",
    "    for each_batch_geometry, each_batch_labels in labeled_dataset:\n",
    "        \n",
    "        \n",
    "        yvalues1 += model.predict(each_batch_geometry).squeeze(1).tolist()\n",
    "        yvalues2 += np.array(each_batch_labels).squeeze(1).tolist()\n",
    "        \n",
    "        ds_iters += 1\n",
    "        \n",
    "        if ds_iters == int(num_training_samples/batch_size):\n",
    "            break\n",
    "    \n",
    "    zippedarray = sorted(zip(yvalues2, yvalues1)) #sorts both lists according to the first one (xvalues2 will be the labels)\n",
    "    sorted_yvalues2 = [x for x,y in zippedarray]\n",
    "    sorted_yvalues1 = [y for x,y in zippedarray]\n",
    "\n",
    "    #Plot \n",
    "    plt.style.use('default')\n",
    "    text_color = 'black'\n",
    "    xvalues = range(0,len(yvalues1))\n",
    "    fig = plt.figure()\n",
    "\n",
    "    if (sort_data == True):\n",
    "        fig1 = plt.plot(xvalues, sorted_yvalues1, label='auxiliary_discriminator_predictions')\n",
    "        fig2 = plt.plot(xvalues, sorted_yvalues2, label='real_labels')\n",
    "\n",
    "    else:\n",
    "        fig1 = plt.plot(xvalues, yvalues1, label='auxiliary_discriminator_predictions')\n",
    "        fig2 = plt.plot(xvalues, yvalues2, label='real_labels')\n",
    "\n",
    "    plt.ylabel('Rating', color=text_color)\n",
    "    plt.xlabel('Data no.', color=text_color)  \n",
    "    plt.rc_context({'xtick.color' : text_color})\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Auxiliary Discriminator Performance\", color=text_color)\n",
    "    #plt.rcParams.update(colors('white'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator_performance(val_ds, sort_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_discriminator_performance(train_ds, sort_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jna2p9QAUWM6",
    "pTegEa4k1RXi"
   ],
   "machine_shape": "hm",
   "name": "210611 - MO_VAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
